
**GAN to Concrete**

This is the pretrained model for  _Béton_, along with its raw image dataset. The model uses deep learning through pix2pix, a conditional generative adversarial network autoencoder.

<div dir="rtl">  
 هذا النموذج طوّر خصيصً لل "أسمنت" (Béton)، و يتضمن مجموعة بياناب خاصة بهذه المادة المستخدمة في البناء. لقد تم استعمال "التعلّم العميق" (Deep Learning) من خلال تقنية ال "pix2pix" وهي مشفر تلقائي (Autoencoder)  قائم على مبدأ ال (cGAN).
</div>


<img width="550" alt="image" src="https://user-images.githubusercontent.com/69199435/96276656-95c27f80-0fd3-11eb-86b7-b37dc675ea76.png">

# Overview  (نظرة عامة)
A collection of photographs showing found  _Béton_ have been stored in a dedicated image dataset. With this dataset, I am exploring ways that _‘Machine Learners’_ refers to humans as much as it does to computers. As a single _‘variable’_ which represents experimentation and fragmentation, _Béton_ can be computationally seen within the ‘Latent Space.’ In this hidden layer of machine learning, input data is broken down and apart, and tries to re-assemble itself by learning possible compositions. While the results are ambiguous, unsupervised learning does help understand, and predict unknown data better.

To visualize the latent space, I feed my image dataset of _Béton_ to a network that de-codes this inner process and generates the re-done _Béton_ back into concrete. 

**[Click here](http://igor.gold.ac.uk/~rhadd001/GANtoBeton/) to see a simulated display for an exhibition.** 
Projection of a photo-grid on an entire wall surface.The photo-grid shuffles through the entire training data, and the predictions of the trained model.
The  _Béton_ sculptures would be displayed physically either on the floor or on plinths.



Project Adjustments to Covid-19 lockdown, and Lebanese Economic/Political/Social Unrest i.e. electricity cuts:

**From Automation to Collaboration :**
Initially, I wanted to build my own network model which would compute the whole process of data input into latent sculpture. The output of the model would have been a step further from a reconstructed visualization as .JPG into an .STL file. The .STL file is a 3D render which is recognized by 3D printers. I was beginning to look into point clouds to automate this process through my model. And finally the .STL would have been rendered to concrete through a 3Dprinter. 
I did not carry on to explore Tensorflow and configure my own GAN, but rather I trained my own model through pix2pix which has its’ pre-set properties. Using my knowledge of python from previous MachineLearning modules. With adjustment, I remained with my Data Input to physical Output idea. Instead of 3D printing a GAN into concrete, I went to a brick factory  and molded a Beton myself following the meticulous designs generated by my model. The concept idea of rendering a neural network to concrete remains as intended, however the process of scultping myself involves more collaboration with the network, rather than giving the project full automation. 

مجموعة من الصور لل"أسمنت" الموجود على الطرقات قد تم اخذها و تخزينها في مجموعة بيانات (Dataset) خاصة بالصور. باستخدامي هذه البيانات، احاول اكتشاف بعض الطرق المستخدمة في "التعلّم الآلي" (Machine Learning) و التي تشير الى الانسان بالقدر نفسه الذي تشير به الى الحاسوب. كمتغير وحيد (Single Variable) يمثل التجربة و التجزئة، يمكن رؤية ال"أسمنت" حاسوبياً في "الفضاء الكامن" (Latent Space). على هذا المستوى، و في هذه الطبقة المخفية للتعلم الآلي، يتم تجزئة البيانات المدخلة (Input Data) و التي تحاول بعدها اعادة تجميع نفسها بطرق مختلفة عن طريق التعلم و بحث الخيارات المتوفرة. نتائج هذه العملية تبقى غامضة و غير ملموسة بشكل كلّيّ، لكنها تساعد بالفعل على فهم و توقع هذه البيانات الغامضة و الغير معروفة بشكل افضل.

لتصور الفضاء الكامن، أُدخل مجموعة البيانات الخاصة بال"أسمنت" (صور) الى شبكة مهمّتها فك تشفير هذه البيانات و من ثم تشكيلها و انشائها بطريقة مختلفة لتشكل صور معدلة للاسمنت.

**[اضغط هنا](http://igor.gold.ac.uk/~rhadd001/GANtoBeton/)** لرؤية عرض محاكٍ للمشروع. ابراز شبكة من الصور على سطح حائط بالكامل. هذه الشبكة تمرّ بشكل متتابع على جميع البيانات الاولية و تبحث في مختلف الاحتمالات الممكنة لتوقع النموذج النهائي (Béton). يتم عرض هذه العملية على الحائط بينما تتواجد فعليّاً منحوتات ال"أسمنت" على الارض او على قاعدة خاصة للعرض.

التعديلات على المشروع بسبب جائحة كورونا و عدم الاستقرار في لبنان على الصعيد السياسي, الاقتصادي و الاجتماعي (انقطاع التيار الكهربائي بشكل مستمر...):

**:من التشغيل الآلي ا التعاون:**
في البداية، اردت بناء نموذج لشبكة خاصة بي مهمتها رقمنة عملية ادخال البيانات و تحويلها الى النموذج الكامن (Latent Sculpture). هذه النتيجة كانت ستكون خطوة ابعد من التصوّر المعاد بناؤه و القائم على ملفات (JPG.) بدلاً من (STL.). ملف الSTL. هو بطبيعته ثلاثي الابعاد 3D و يتم رصده و تمييزه في الطابعات ثلاثية الابعاد (3D Printers). كنت قد بدأت البحث في ال"Point Clouds" لجعل هذه العملية آلية و من ثم تحويل ملف الSTL. الى "اسمنت" من خلال ال3D Printer.
لم اكمل مسعايَ هذا و الذي كان سيؤدي بي الى استكشاف الTensorflow لتهيئة و ترتيب الGAN الخاص بي، لكنني بدأت و درّبت نموذجاً خاصاً بي عن طريق الpix2pix و الذي يحتوي على خصائص معدَّة مسبقاً، و ذلك بإستخدام معرفتي لبرنامج Python من خلال المواد الخاصة بالتعلّم الآلي التي اخترتها في سنوات دراستي. مع بعض التعديلات، حافظت على فكرتي القائمة على تحويل البيانات المدخلة الى نتيجة ملموسة. بدلاً من طباعة الGAN بشكل اسمنتيّ ثلاثي الابعاد، ذهبت الى معمل لتصنيع قوالب الطوب و صنّعت (Molded) قالب اسمنت بنفسي و ذلك بإتباع تفاصيل التصميم الناتج عن النموذج الذي تحصّلت عليه من خلال التعلّم الآلي. فكرة تحويل شبكة عصبيّة (Neural Network) الى "أسمنت" يبقى كما كان مخططاً له منذ البداية لكن المعالجة من خلال بنائي و نحتي لتصميم خاص بي يحتاج الى تعاون اكبر مع الشبكة بدلاً من جعل المشروع مشَغّل آلياً بالكامل.


# Data (البيانات)
<img width="754" alt="image" src="https://user-images.githubusercontent.com/69199435/96276954-efc34500-0fd3-11eb-88ef-4322e12f0d0e.png">


The Beton Dataset is a collection of self-taken photos of  _Béton_ spontaneously found throughout the city of Beirut and its outskirts. 

Scraping images from large online databases is the conventional way to collect images to work with GANS. Deep learning goes hand in hand with big data, as it deals with extracting meaningful information from a vast amount of information. Memo Aktins [Deep Mediations](https://www.memo.tv/works/deep-meditations/) illustrates GAN’s as a powerful medium for creative expression. Where his image dataset consist of ‘everything’. All scraped from Flickr with tags such as ‘life, love, faith, everything, etc.’. 
The power of GANs to learn the distribution of all of its input data,  and to find forms, compositions, and patterns within its endless network of possible trajectories makes it a fascinating tool to understand big data better, and distinguishes it from other algorithms. 

My raw image dataset currently consists of about only 40 original images. The model however has been trained on a  total of 274 images, consisting of re-sized, cropped, rotated, and transformed adjustments from the original dataset. I then ran a batch process to rescale the images to 256x256. The method used for training is ‘inpainting’ from pix2pix-tensorflow. 
Creating the Beton dataset manually was by choice firstly because data mining is restricted to digitized and transparent information, and the definition I see _Béton_ in falls out of its categorization within construction-sites. The dataset grew as i came across different uses of  _Béton_, and it was never by intention to search for them. I did also receive images by text from others who would come across one. Getting the data was a very material and lived-in process. 

مجموعة بيانات ال"أسمنت" تمّ تصويرها و اخذها بشكل عفويّ عبر ايجاد قوالب من الBéton في مختلف مناطق و شوارع مدينة بيروت.

أخذ الصور عبر الانترنت من مجموعات بيانات كبيرة هي الطريقة المثلى لتجميع الصور التي تناسب الGANS. التعلّم العميق (Deep Learning) يعمل بشكل متوازٍ مع البيانات الضخمة (Big Data)، فهو يستخرج معلومات مهمّة ذا معنى من خلال البحث في كمّيات كبيرة من المعلومات. Memo Atkins Deep Meditations يُظهر الGANS كوسيلة فعّالة للتعبير الابداعي حيث مجموعة صوَرِه تشمل كل شيء موجود على الانترنت: يتمّ اختيار الصور و استخراجها من Flickr حيث تحمل عدّة توصيفات (Tags) كالحبّ، الحياة، الايمان، الخ...
قوّة و فعالية الGANS في تعلّم كيفيّة توزيع بياناته المُدخلة، و ايجاد مختلف الاشكال و التراكيب و الانماط عبر استخدام شبكته اللامتناهية للطرق المحتملة يجعل منه اداة مذهلة تساعد على فهم البيانات الضخمة بشكل افضل و يميّزه عن الخوارزميات (Algorithms) الاخرى.

مجموعة بياناتي و صوري لا تشكّل حالياً اكثر من 40 صورة اصليّة. لكنّ النموذج قد تمّ تدريبه بإستخدام 274 صورة، هي كلّها نتيجة تغيير حجم و تعديل و قلب الصور الاصليّة لمجموعة البيانات. فيما بعد، قمت بعملية تغيير حجم الصور الى 256x256. الطريقة التي اعتُمِدت في هذه العمليّة هي 'inpainting' من pix2pix-tensorflow.
خلق مجموعة بيانات ال"اسمنت" يدويّاً كان قد تمّ اختياره اوّلاً بسبب طبيعة البحث و التنقيب عن البيانات (Data Mining) القائمة على العمل حصرياً مع المعلومات الرقميّة و الشفّافة، و ثانيّاً بسبب رؤيتي للتعريف بال"أسمنت" خارجاً عن التصنيف التقليدي الذي تضعه ورشات البناء. مجموعة البيانات كبرت في خلال عملي على المشروع حيث وجدّت عدّة استخدامات للBéton و ذلك من دون التقصّي عمداً عن هذه الاختلافات للإستعمال. بالإضافة الى ذلك، تلقّيت صوراً من اشخاص آخرين حيث كانوا يجدون ال"أسمنت" و يرسلونه لي عبر رسائل نصيّة و الكترونيّة. تجميع الصور و البيانات كانت عمليّة ممتعة
و مشوّقة جدّاً.

# Latent Variables and _Béton_ (المتغيّرات الكامنة)
From Classification algorithms that distribute entities into decision boundaries, to optimization models that maximize the objective function. Information is fed to the machine in hope that it can find relevant features, when however, the network is also demanding features of relevant information. In this case, humans and machines must deal with the same problem. 
In a recent book on Machine Learning titled “Machine Learners” Adrian Mackenzie writes
 > “Who or what is a machine learner? I am focusing on machine learners—a term that refers to both humans and machines or human-machine relations.” 
 
Mackenzie uses the term machine learner to refer to the machine as much as to the learning human. While human-machine collaborations become frequented , Machine Learners perform an accumulation of data, and both humans and machines make biases.And so, the question of how to respond to unexpected situations remains as challenging. When a situation and its entities become un-recognizable, the biases begin to challenge themselves as they must redistribute their ideas within experimentation. The stage of experimentation is crucial in allowing and engaging with for different possibilities. I make analogies to this space through latency in computing, and through the use of Béton in Lebanon. 

The space where the network is learning the distributions of its data is called the Latent Space. Within the latent space, neural nets autoencodes its data into really low resolution, and this low res data becomes the material it uses to interpolate through the form and composition of varying data inputs. In times of necessity, the Béton suddenly comes to life as it becomes re-purposed and re-identified. It fills cracked spaces that only adaptation can mend through. Its necessity cannot come from an optimized objective function, as it has de-routed relevance from another point of interest. It is comparable to a latent variable, broken up and dispersed, as it combines to different forms and compositions when spotted. Unpredicted situations forces set biases to be challenged, and stirs them to find new possibilities. 
> “Unsupervised algorithms are used often in an exploratory setting when a data scientist wants to understand the data better, because there is no way to “tell” the algorithm what we are looking for. 
Constraining an autoencoder during training(example:adding noise) pushes it to discover patterns in the data.” 

"تُستعمل الخوارزميات الغير مُشرف عليها غالباً في جوّ استكشافي خصوصاً من قبل علماء البيانات الذين يبحثون عن فهم بياناتهم بشكل افضل، حيث لا توجد طريقة لتلقيم الخوارزمية و اخبارها عمّا نبحث عنه.

إضافة قيود على المشفّر التلقائي (ضجيج مثلاً) خلال التدريب تدفعه الى اكتشاف انماط مختلفة في البيانات."

من خوارزميات التصنيف التي توزّع الجهات ضمن حدود القرار، الى نماذج محسنّة تؤمّن اقصى قدر من تحقيق الهدف. يتّم ادخال المعلومات الى الآلة على امل ايجاد ميزات ذات صلّة، حيث في المقابل تطلب الشبكة ايضاً ميزات ذات صلة بالمعلومات. في هذه الحالة، على الانسان و الآلة التعامل مع نفس المشكلة.
في كتابه الصادر حديثاً عن التعلّم الآلي "Machine Learners"، يكتب Adrian Mackenzie:
 > "من او ما هو المتعلّم الآلي (Machine Learner)؟ انني اركّز على المتعلمين الآليين - مصطلح يشير الى الانسان و الآلة معاً او الى العلاقة بين الانسان و الآلة."

يستخدم Mackenzie مصطلح "المتعلّم الآلي" للإشارة الى الآلة بالقدر نفسه الذي يشير به الى الانسان الذي يبحث عن العلم. و عندما يصبح التعاون بين الانسان و الآلة متكرراً، يراكم المتعلمون الآليّون البيانات، و يشكّل الإثنان معاً مجموعة من التحيّزات. لذلك يبقى السؤال عن كيفية الردّ على المواقف غير المتوقعة يشكّل تحدّياً كبيراً. عندما يصبح الموقف و جهاته غير قابلين للتعرّف عليهما، تبدأ التحيّزات في تحدّي نفسها حيث تسعى الى اعادة توزيع افكارها من خلال التجربة. مرحلة التجربة مصيريّة لتمكين ايجاد احتمالات مختلفة. أقوم بإجراء تشبيهات لهذا الفضاء عبر وقت الاستجابة للعمليّات الحاسوبيّة، و من خلال استعمال الBéton في لبنان.

الفضاء الذي تتعلّم فيه الشبكة طريقة توزّع بياناتها يُعرف بالفضاء الكامن (Latent Space). في حدود هذا الفضاء، تشفّر الشبكات العصبيّة تلقائياً بياناتها الى مستوى دقّة متدنّي جداً، و تصبح هذه البيانات المادة التي تستخدمها الشبكات العصبية للتوفيق بين الشكل و التكوين لمختلف البيانات المُدخلَة. في اوقات الحاجة، يُولد ال"أسمنت" فجأة حيث يظهر بأهداف و وظائف جديدة. يملأ فراغات و تشقّقات في الفضاء، وحده التكيّف (Adaptation) قادر على ملئها و اصلاحها. حاجته لا يمكن ان تأتي من وظيفة موضوعيّة محسّنة، حيث لديه صلة ملاءمة موجّهة بشكل آخر من حيث نقطة الاهتمام. يمكن تشبيهه بمتغيّر كامن (Latent Variable)، مقسّم الى اجزائه و مبعثر، حيث يجمّع نفسه بأشكال و تكاوين مختلفة. المواقف التي لا يمكن توقّعها تُجبر التحيّزات المعدّة مسبقاً لتحدّي نفسها و تدفعها لإيجاد إحتمالات جديدة.


# Rendering a Neural Network to Concrete (تحويل شبكة عصبيّة الى أسمنت)
<img width="751" alt="image" src="https://user-images.githubusercontent.com/69199435/96277062-12edf480-0fd4-11eb-9cd8-69381fb19813.png">

Visualised reconstructions generated by my model where used as reference to manipulate a concrete slab. 
 
I went to the factory where they make concrete slabs. The factory makes some in bulk every morning and piles them in a row until they dry within a day. To manipulate or mold the concrete smoothly, I had about 5 minutes after it was taken out of the cast before the block would shatter instead of mend. 
The concrete block has a very common shape and use, it is either a perfect block, or it is a bit shattered down or broken. But it is never slightly morphed or bended with smooth curves. The fact that it dries so quickly explained it. The morphed _Béton_ did startle some people who saw it, wondering what it was, or how it came to be. I am excited by this possibility of having a morphed _Béton_, it certainly does feel uncanny. Without the direction and vision of the GAN I would not have known how to mend the block. It could have easily looked like shattered stone, but the GAN highlighted and emphasized the main features to be manipulated. 


تم استخدام الاشكال و التصوّرات المُعاد بناؤها عبر النموذج كمرجع لتشكيل لوح من ال"اسمنت".

ذهبتُ اليوم الى المصنع حيث يتمّ تصنيع الواح ال"اسمنت". المصنع يقوم بإعداد هذه الالواح بكمّيات كبيرة في كلّ صباح و من ثمّ يضعهنّ في صفّ حتّى الجفاف مدّة يوم واحد: لمعالجة ال"اسمنت" او تشكيله بطريقة سلسة. كان لدي قرابة الخمس دقائق بعد اخراج قالب ال"اسمنت" من النار من اجل تشكيله بدل تحطّمه و تفتّته. لدى قالب ال"اسمنت" شكل و استعمال شائعيْن، إمّا كقالب مثالي، او كقطعة مفتّتة قليلاً او محطّمة. لكنّ لا يتّم ابداً قولبته بشكل ملتوٍ مع انحناءات سلسة. و يمكن تفسير هذا بسبب سرعة جفاف هذه المادة. استوقف ال"اسمنت" المُحوّل مع انحناءات بعض الناس الذين رأوه متسائلين عن ماهيته و كيفية تحوّله لهذا الشكل. إنّني متحمّسة لقدرتي جزئيّاً على التلاعب بقالب ال"اسمنت" كما يحلو لي حيث تبدو هذه الامكانيّة غريبة بعض الشيء. من دون توجيه و رؤية الGAN لما استطعت معرفة كيفية تشكيل القالب. كان من السهل جداً جعل القالب يبدو محطّماً، لكن الGAN اوضح و شدّد لي الميزات الاساسية التي يجب التركيز عليها



# Using the Model
The dataset can be updated and the model further trained. The model may also be used to generate a latent conversion on new input data (ie. a single image or more), by doing a test run.

### Further Train the model
Open Terminal or command prompt, and cd into cloned or downloaded pix2pix.
```ruby
# clone pix2pix library
git clone https://github.com/affinelayer/pix2pix-tensorflow.git
cd pix2pix-tensorflow
# clone Beton Dataset within pix2xpix library 
git clone https://gitlab.doc.gold.ac.uk/rhadd001/beton.git
#(Before training, you may just add source photos to the Beton_ImageDataset and git push back into the source code)

#Prepare Images for model, Add photo to the ‘original’ folder >> /beton/pix2pix_model/betonphotos/original 

#Pre-process data for in-painting method. 

#Resize source images
python tools/process.py \
  --input_dir betonphotos/original \
  --operation resize \
 —output_dir photos/resized
# Create images with blank centers
python tools/process.py \
  --input_dir betonphotos/resized \
  --operation blank \
  --output_dir betonphotos/blank
# Combine resized imaged with blanked images
python tools/process.py \
  --input_dir betonphotos/resized \
  --b_dir betonphotos/blank \
  --operation combine \
  --output_dir betonphotos/combined
# Split into train/val set
python tools/split.py \
  --dir betonphotos/combined

# Train the model (took me more than 10 hours on a MacBook pro. 2 days if max_epochs=200)
python pix2pix.py \
  --mode train \
  --output_dir beton_train \
  --max_epochs 50 \
  --input_dir betonphotos/combined/train \
  --which_direction BtoA
# Test the model
python pix2pix.py \
  --mode test \
  --output_dir beton_test \
  --input_dir betonphotos/combined/val \
  --checkpoint beton_train
```
### **Input own data without training**

First, Follow the steps above, by pre-processing your photo. (Resize to 256x256, make a Blank center, and create an image pair.) 
Put your image pair in its own folder ‘myimage’, and test the model as above with two adjustment to the input and output directory.
```ruby  
  --output_dir mytest\
  --input_dir betonphotos/myimage\
```
This will result with a new file ’mytest’ that has an HTML file including an input/output/target image made by the model.

<img width="867" alt="image" src="https://user-images.githubusercontent.com/69199435/96277265-4e88be80-0fd4-11eb-95da-0e7e1cf947b4.png">


***Arabic Translation by Jad Chehimi*



# **References** 

## _Code Tutorials_
[Gene Kogan tutorial guide for pix2pix](https://ml4a.github.io/guides/Pix2Pix/)

[Memo Aktens webcam-pix2pix-tensorflow](https://github.com/memo/webcam-pix2pix-tensorflow)

[Christpher Hesse pix2pix tutorial using Facades dataset](https://github.com/affinelayer/pix2pix-tensorflow)

## _Technical Papers_
[Akten, Memo, et al. _Learning to See: You Are What You See_, 2019.](http://research.gold.ac.uk/26671/)

[Akten, Memo. _Deep meditations_, 2018. ](https://medium.com/@memoakten/deep-meditations-meaningful-exploration-of-ones-inner-self-576aab2f3894)

[Isola, Philip, et al._Image-to-Image Translation with Conditional Adversarial Networks_, 2016](https://arxiv.org/pdf/1611.07004v1.pdf)

## _Literature_
Bowker, Geoffrey C., and Susan Leigh Star. _Sorting Things out : Classification and Its Consequences._ MIT Press, 1999.

Beauvoir, Simone de. _Pour Une Morale De L'ambiguïté : Suivi De Pyrrhus Et Cineas._ Gallimard, 1947.

Mackenzie, Adrian. _Machine Learners : Archaeology of a Data Practice._ 2017.


